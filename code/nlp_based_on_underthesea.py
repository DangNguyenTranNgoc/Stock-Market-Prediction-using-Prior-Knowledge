# -*- coding: utf-8 -*-
"""NLP Based on Underthesea

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pXFfDavROenwtk1kD1gIxA2DQk_2NZf8

# RÚT TRÍCH THÔNG TIN VĂN BẢN (INFORMATION EXTRACTION)

# RÚT TRÍCH SẮC THÁI CỦA CÂU (SENTIMENT EXTRACTION)


#### Nhóm 1:

1.   Hà Minh Tuấn          - 20C29041
2.   Nguyễn Thanh Thoại    - 20C29039
3.   Trần Ngọc Đăng Nguyên - 20C29011
"""

! pip install underthesea

! underthesea download-model SA_GENERAL
! underthesea download-model SA_BANK

! underthesea list-data

! underthesea download-data UTS2017-BANK

!underthesea list-model

import unidecode
from sklearn.base import BaseEstimator, TransformerMixin
import string
import re
from underthesea.word_tokenize.regex_tokenize import tokenize

negative_emoticons = {':(', '☹', '❌', '👎', '👹', '💀', '🔥', '🤔', '😏', 
                      '😐', '😑', '😒', '😓', '😔', '😕', '😖', '😞', '😟',
                      '😠', '😡', '😢', '😣', '😤', '😥', '😧', '😨', '😩', 
                      '😪', '😫', '😭', '😰', '😱', '😳', '😵', '😶', '😾', 
                      '🙁', '🙏', '🚫', '>:[', ':-(', ':(', ':-c', ':c', ':-<', 
                      ':っC', ':<', ':-[', ':[', ':{'}

positive_emoticons = {'=))', 'v', ';)', '^^', '<3', '☀', '☺', '♡', '♥', '✌', 
                      '✨', '❣', '❤', '🌝', '🌷', '🌸', '🌺', '🌼', '🍓', 
                      '🎈', '🐅', '🐶', '🐾', '👉', '👌', '👍', '👏', '👻', 
                      '💃', '💄', '💋', '💌', '💎', '💐', '💓', '💕', '💖', 
                      '💗', '💙', '💚', '💛', '💜', '💞', ':-)', ':)', ':D', 
                      ':o)', ':]', ':3', ':c)', ':>', '=]', '8)'}

class Lowercase(BaseEstimator, TransformerMixin):
    def transform(self, x):
        return [s.lower() for s in x]

    def fit(self, x, y=None):
        return self

class RemoveTone(BaseEstimator, TransformerMixin):
    def remove_tone(self, s):
        return unidecode.unidecode(s)

    def transform(self, x):
        return [self.remove_tone(s) for s in x]

    def fit(self, x, y=None):
        return self

class CountEmoticons(BaseEstimator, TransformerMixin):
    def count_emoticon(self, s):
        positive_count = 0
        negative_count = 0
        for emoticon in positive_emoticons:
            positive_count += s.count(emoticon)
        for emoticon in negative_emoticons:
            negative_count += s.count(emoticon)
        return positive_count, negative_count

    def transform(self, x):
        return [self.count_emoticon(s) for s in x]

    def fit(self, x, y=None):
        return self

import os
import shutil
import time
from pathlib import Path

from underthesea.corpus.categorized_corpus import CategorizedCorpus
from underthesea.data_fetcher import (
    DataFetcher, 
    NLPData
)
from underthesea.models.text_classifier import (
    TextClassifier, 
    TEXT_CLASSIFIER_ESTIMATOR
)
from underthesea.trainers import ModelTrainer

from sklearn.feature_extraction.text import (
    CountVectorizer, 
    TfidfVectorizer
)
from sklearn.metrics import f1_score
from sklearn.pipeline import (
    Pipeline, 
    FeatureUnion
)
from sklearn.svm import SVC

'''
Can't get this class from the FW, so we need to create a new here ಥ﹏ಥ 
'''
import json
import warnings

# ignore warnings when using transformer
# see: https://github.com/scikit-learn/scikit-learn/issues/12327
from underthesea.corpus import Corpus
from underthesea.models.text_classifier import (
    TextClassifier,
    TEXT_CLASSIFIER_ESTIMATOR
)
from sklearn.metrics import f1_score
from sklearn.preprocessing import LabelEncoder
from os.path import join
import joblib

warnings.simplefilter("ignore", category=PendingDeprecationWarning)

class ClassifierTrainer:

    def __init__(self, classifier: TextClassifier, corpus: Corpus):
        self.classifier = classifier
        self.corpus = corpus

    def train(self, model_folder: str, scoring=f1_score):
        score = {}
        multilabel = self.classifier.multilabel
        metadata = {"estimator": self.classifier.estimator.value, 
                    "multilabel": multilabel}
        train, dev, test = self._convert_corpus(self.corpus, 
                                                multilabel=multilabel)
        X_train, y_train = train
        X_dev, y_dev = dev
        X_test, y_test = test

        if self.classifier.estimator == TEXT_CLASSIFIER_ESTIMATOR.SVC:
            transformer = self.classifier.params['vectorizer']

            X_train = transformer.fit_transform(X_train)
            joblib.dump(transformer, join(model_folder, "x_transformer.joblib"))

            y_transformer = LabelEncoder()
            y_train = y_transformer.fit_transform(y_train)
            joblib.dump(y_transformer, join(model_folder, "y_transformer.joblib"))

            estimator = self.classifier.params['svc']
            estimator.fit(X_train, y_train)
            joblib.dump(estimator, join(model_folder, "estimator.joblib"))

            X_dev = transformer.transform(X_dev)
            y_dev = y_transformer.transform(y_dev)
            y_dev_pred = estimator.predict(X_dev)
            dev_score = scoring(y_dev, y_dev_pred)

            X_test = transformer.transform(X_test)
            y_test = y_transformer.transform(y_test)
            y_test_pred = estimator.predict(X_test)
            test_score = scoring(y_test, y_test_pred)
            score["dev_score"] = dev_score
            score["test_score"] = test_score
            print("Dev score:", dev_score)
            print("Test score:", test_score)

        if self.classifier.estimator == TEXT_CLASSIFIER_ESTIMATOR.PIPELINE:
            pipeline = self.classifier.pipeline
            if self.classifier.multilabel:
                y_train = self.classifier.y_encoder.fit_transform(y_train)
                joblib.dump(self.classifier.y_encoder, 
                            join(model_folder, "y_encoder.joblib"))
            pipeline.fit(X_train, y_train)
            joblib.dump(pipeline, join(model_folder, "pipeline.joblib"))

            y_dev_pred = pipeline.predict(X_dev)
            if self.classifier.multilabel:
                dev_score = scoring(self.classifier.y_encoder.transform(y_dev), 
                                    y_dev_pred)
            else:
                dev_score = scoring(y_dev, y_dev_pred)

            y_test_pred = pipeline.predict(X_test)
            if self.classifier.multilabel:
                test_score = scoring(self.classifier.y_encoder.transform(y_test), 
                                     y_test_pred)
            else:
                test_score = scoring(y_test, y_test_pred)
            score["dev_score"] = dev_score
            score["test_score"] = test_score
            print("Dev score:", dev_score)
            print("Test score:", test_score)

        with open(join(model_folder, "metadata.json"), "w") as f:
            content = json.dumps(metadata, ensure_ascii=False)
            f.write(content)
        return score

    def _convert_corpus(self, corpus: Corpus, multilabel=False):
        X_train = [s.text for s in corpus.train]
        X_dev = [s.text for s in corpus.dev]
        X_test = [s.text for s in corpus.test]
        if multilabel:
            y_train = [[label.value for label in s.labels] for s in corpus.train]
            y_dev = [[label.value for label in s.labels] for s in corpus.dev]
            y_test = [[label.value for label in s.labels] for s in corpus.test]
        else:
            y_train = [s.labels[0].value for s in corpus.train]
            y_dev = [s.labels[0].value for s in corpus.dev]
            y_test = [s.labels[0].value for s in corpus.test]
        return (X_train, y_train), (X_dev, y_dev), (X_test, y_test)

model_folder = "tmp/classification_svm_uts2017_bank"
try:
    shutil.rmtree(model_folder)
except:
    pass
finally:
    os.makedirs(model_folder)

lower__ngram_range = (1, 3)
with_tone__ngram_range = (1, 4)
remove_tone__ngram_range = (1, 4)
count__max_features = 4000
estimator__C = 0.75

start = time.time()
print(">>> Train UTS2017_BANK Classification")

# Fix bug folder's name. Defined names are on lowercase format,
# but actually are uppercase.
#data_folder = Path("/root/.underthesea") / "datasets" / "UTS2017-BANK"
data_folder = Path("/content/tmp") / "data"
corpus: CategorizedCorpus = DataFetcher.load_classification_corpus(data_folder)
print("\n\n>>> Sample sentences")

for s in corpus.train[:10]:
    print(s)

pipeline = Pipeline(
    steps=[
        ('features', FeatureUnion([
            ('lower_pipe', Pipeline([
                ('lower', Lowercase()),
                ('tfidf', TfidfVectorizer(ngram_range=lower__ngram_range, 
                                          norm='l2', 
                                          min_df=2, 
                                          max_features=count__max_features))])),
            ('with_tone_char', TfidfVectorizer(ngram_range=with_tone__ngram_range, 
                                               norm='l2', 
                                               min_df=2, 
                                               analyzer='char')),
            ('remove_tone', Pipeline([
                ('remove_tone', RemoveTone()),
                ('lower', Lowercase()),
                ('tfidf', TfidfVectorizer(ngram_range=remove_tone__ngram_range, 
                                          norm='l2', min_df=2))])),
            ('emoticons', CountEmoticons())
        ])),
        ('estimator', SVC(kernel='linear', 
                          C=estimator__C, 
                          class_weight=None, 
                          verbose=True,
                          probability=True))
    ]
)
classifier = TextClassifier(estimator=TEXT_CLASSIFIER_ESTIMATOR.PIPELINE, 
                            pipeline=pipeline)
model_trainer = ClassifierTrainer(classifier, corpus)


def micro_f1_score(y_true, y_pred):
    return f1_score(y_true, y_pred, average='micro')


model_trainer.train(model_folder, scoring=micro_f1_score)
print(f"\n\n>>> Finish training in {round(time.time() - start, 2)} seconds")
print(f"Your model is saved in {model_folder}")

from underthesea.corpus.data import Sentence
from underthesea.models.text_classifier import TextClassifier, TEXT_CLASSIFIER_ESTIMATOR

model_folder = "tmp/classification_svm_uts2017_bank"
print(f"Load model from {model_folder}")
classifer = TextClassifier.load(model_folder)
print(classifer.estimator)
print(f"Model is loaded.")


def predict(text):
    print(f"\nText: {text}")

    sentence = Sentence(text)
    classifer.predict(sentence)
    labels = sentence.labels
    print(f"Labels: {labels}")


predict('Dịch vụ tốt, 5 sao')

custom_classifer = joblib.load(join(model_folder, "pipeline.joblib"))

def predict_score(str):
  pred = custom_classifer.predict_proba([str])
  max_index = pred[0].argmax()

  # FIN#negative
  if max_index == 0:
    return 0 - pred[0][max_index]
  #FIN#positive
  if max_index == 2:
    return pred[0][max_index]
  return 0

predict_score('Thị trường tăng trưởng, VNIndex tăng 5 điểm')

import pandas as pd

file_path = r'/content/drive/MyDrive/Data/stock-market-prediction/news_cafef.csv'
data = pd.read_csv(file_path, index_col=0)
data['Sentiment'] = 0.0
data

for index, row in data.iterrows():
  score = predict_score(row['Title'])
  print('Index: {} / Score: {}'.format(index, score))
  data.at[index, 'Sentiment'] = score

data

data_folder = r'/content/drive/MyDrive/Data/stock-market-prediction'
data.to_csv('{}/news_cafef_scored.csv'.format(data_folder))

"""### Sentiment Analysis Scoring for 'vnexpress'"""

file_path = r'/content/drive/MyDrive/Data/stock-market-prediction/news_vnexpress.csv'
data = pd.read_csv(file_path, index_col=0)
data['Sentiment'] = 0.0
data

for index, row in data.iterrows():
  score = predict_score(row['Title'])
  print('Index: {} / Score: {}'.format(index, score))
  data.at[index, 'Sentiment'] = score

data_folder = r'/content/drive/MyDrive/Data/stock-market-prediction'
data.to_csv('{}/news_vnexpress_scored.csv'.format(data_folder))

custom_classifer.classes_